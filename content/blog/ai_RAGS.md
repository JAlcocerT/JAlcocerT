---
title: "My Favourite ways to RAG"
date: 2025-04-06T10:20:21+01:00
draft: false
tags: ["Dev","Python"]
description: 'RAG applications.'
url: 'comparing-rag-and-use-cases'
---


{{< cards cols="1" >}}
  {{< card link="https://jalcocert.github.io/JAlcocerT/ai-projects-python-dependencies/" title="Python Deps 101" >}}
{{< /cards >}}



{{< cards >}}
  {{< card link="https://jalcocert.github.io/JAlcocerT/get-started-with-flask/" title="Flask Intro" image="/blog_img/apps/flask-nginx-duckdns.png" subtitle="Deployed a Flask WebApp with https and NGINX to Hertzner" >}}
  {{< card link="https://github.com/JAlcocerT/flask_sensor_display" title="Flask Sensor Display" image="/blog_img/apps/gh-jalcocert.svg" subtitle="Source Code on Github" >}}
{{< /cards >}}


## LangChain


{{< callout type="info" >}}
And actually the build has happened faster than for streamlit Apps
{{< /callout >}}

### With Persistent ChromaDB and MD


[NLTK](https://github.com/nltk/nltk) was key!


https://pypi.org/project/nltk/
https://www.nltk.org/api/nltk.tag.perceptron.html


> And I almost forgot, but used it as NLP Tool


{{< filetree/container >}}
  {{< filetree/folder name="FlaskProject" >}}
    {{< filetree/file name="app.py" >}}
    {{< filetree/folder name="templates" state="open" >}}
      {{< filetree/file name="index.html" >}}
    {{< /filetree/folder >}}
  {{< /filetree/folder >}}
{{< /filetree/container >}}


![alt text](/blog_img/GenAI/chromadb-cli.png)

### CSV

### PDF

### Database


## LLamaIndex


## PandasAI


---

## Conclusions




## FAQ

MLflow on Databricks: Review how MLflow is integrated into Databricks for tracking machine learning experiments, managing models, and deploying them. Understand concepts like runs, experiments, and the model registry.

### AI Keys

Lately I have been using:

* https://claude.ai/



### GEN AI Techniques


Fundamentals of Neural Networks: Understand the architecture and training of deep neural networks.
Generative Adversarial Networks (GANs): Basic understanding of how GANs work for generating synthetic data or other creative outputs.
Variational Autoencoders (VAEs): Another type of generative model.
Transformer Networks: Deep dive into the architecture of Transformers, which are the foundation for many state-of-the-art NLP and generative models (e.g., BERT, GPT).
Large Language Models (LLMs): Understand the capabilities and limitations of LLMs and how they can be applied to HR-related tasks.