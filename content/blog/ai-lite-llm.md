---
title: "[AI] Using LiteLLM to unify LLMs calls"
date: 2024-12-25
draft: true
# cover:
#     image: "https://socialify.git.ci/alejandro-ao/ask-multiple-pdfs/image?description=1&font=Inter&language=1&name=1&stargazers=1&theme=Auto"
#     alt: "ChatPDF" # alt text
#     caption: "SelfHosting A RAG App to chat with PDFs." # display caption under cover
tags: ["Gen-AI","Python"]
description: 'How to use LiteLLM with different APIs - From OpenAI to Mistral APIs'
summary: 'Setup LiteLLM to make LLMs API calls.'
url: 'how-to-use-lite-llm'
---


* https://github.com/BerriAI/litellm


> Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]


## About LLMs APIs

### OpenAI

* https://platform.openai.com/api-keys

### Anthropic

* https://console.anthropic.com/workbench/

### Groq

* Get your Groq API for the app <https://console.groq.com/keys>

### Ollama

You can setup [Ollama, even with UI](https://fossengineer.com/ollama-web-ui/)

### MistralAPI

## Conclusions

This very cool library can simplify AI Apps like the multichat I built.

As it can unify the API calls across different providers

---

## FAQ

